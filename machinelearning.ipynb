{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/processed/201901.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>backers_count</th>\n",
       "      <th>blurb</th>\n",
       "      <th>country</th>\n",
       "      <th>created_at</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>id</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>...</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "      <th>state_changed_at</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>parent_category</th>\n",
       "      <th>category</th>\n",
       "      <th>project_url</th>\n",
       "      <th>rewards_url</th>\n",
       "      <th>project_duration</th>\n",
       "      <th>time_til_state_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>An eco-friendly coffee table that is both func...</td>\n",
       "      <td>US</td>\n",
       "      <td>2016-09-11 22:05:51</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-12-05 19:42:23</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1504859185</td>\n",
       "      <td>2016-11-05 18:42:23</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>2016-12-05 19:42:23</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>crafts</td>\n",
       "      <td>woodworking</td>\n",
       "      <td>https://www.kickstarter.com/projects/983022919...</td>\n",
       "      <td>https://www.kickstarter.com/projects/983022919...</td>\n",
       "      <td>84 days 21:36:32.000000000</td>\n",
       "      <td>84 days 21:36:32.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>We take digital uploads and make them handpain...</td>\n",
       "      <td>CA</td>\n",
       "      <td>2015-07-10 14:59:32</td>\n",
       "      <td>CAD</td>\n",
       "      <td>2015-08-24 12:00:34</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>49266114</td>\n",
       "      <td>2015-07-21 12:00:34</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>2015-08-24 12:00:34</td>\n",
       "      <td>247.950175</td>\n",
       "      <td>art</td>\n",
       "      <td>painting</td>\n",
       "      <td>https://www.kickstarter.com/projects/101531536...</td>\n",
       "      <td>https://www.kickstarter.com/projects/101531536...</td>\n",
       "      <td>44 days 21:01:02.000000000</td>\n",
       "      <td>44 days 21:01:02.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>243</td>\n",
       "      <td>We are a team of restaurant pros looking to fu...</td>\n",
       "      <td>US</td>\n",
       "      <td>2015-03-24 17:41:14</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-05-15 16:22:34</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>1228074690</td>\n",
       "      <td>2015-04-15 16:22:34</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>successful</td>\n",
       "      <td>2015-05-15 16:22:34</td>\n",
       "      <td>41738.000000</td>\n",
       "      <td>food</td>\n",
       "      <td>food trucks</td>\n",
       "      <td>https://www.kickstarter.com/projects/372111659...</td>\n",
       "      <td>https://www.kickstarter.com/projects/372111659...</td>\n",
       "      <td>51 days 22:41:20.000000000</td>\n",
       "      <td>51 days 22:41:20.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Loosely-based on a Lakota legend, Grandfather ...</td>\n",
       "      <td>US</td>\n",
       "      <td>2017-05-18 12:30:32</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-07-16 15:03:03</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>330962986</td>\n",
       "      <td>2017-06-01 15:03:03</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>2017-07-16 15:03:04</td>\n",
       "      <td>3115.000000</td>\n",
       "      <td>publishing</td>\n",
       "      <td>children's books</td>\n",
       "      <td>https://www.kickstarter.com/projects/133655246...</td>\n",
       "      <td>https://www.kickstarter.com/projects/133655246...</td>\n",
       "      <td>59 days 02:32:31.000000000</td>\n",
       "      <td>59 days 02:32:32.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Save me is a feature film about a depression s...</td>\n",
       "      <td>IE</td>\n",
       "      <td>2015-12-14 19:38:41</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2016-02-13 01:56:30</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>1657821447</td>\n",
       "      <td>2015-12-15 01:56:30</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>canceled</td>\n",
       "      <td>2016-02-10 00:54:26</td>\n",
       "      <td>660.680598</td>\n",
       "      <td>film &amp; video</td>\n",
       "      <td>movie theaters</td>\n",
       "      <td>https://www.kickstarter.com/projects/203240363...</td>\n",
       "      <td>https://www.kickstarter.com/projects/203240363...</td>\n",
       "      <td>60 days 06:17:49.000000000</td>\n",
       "      <td>57 days 05:15:45.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  backers_count  \\\n",
       "0           0              1   \n",
       "1           1              3   \n",
       "2           2            243   \n",
       "3           3             27   \n",
       "4           4              3   \n",
       "\n",
       "                                               blurb country  \\\n",
       "0  An eco-friendly coffee table that is both func...      US   \n",
       "1  We take digital uploads and make them handpain...      CA   \n",
       "2  We are a team of restaurant pros looking to fu...      US   \n",
       "3  Loosely-based on a Lakota legend, Grandfather ...      US   \n",
       "4  Save me is a feature film about a depression s...      IE   \n",
       "\n",
       "            created_at currency             deadline     goal          id  \\\n",
       "0  2016-09-11 22:05:51      USD  2016-12-05 19:42:23   5000.0  1504859185   \n",
       "1  2015-07-10 14:59:32      CAD  2015-08-24 12:00:34   1000.0    49266114   \n",
       "2  2015-03-24 17:41:14      USD  2015-05-15 16:22:34  35000.0  1228074690   \n",
       "3  2017-05-18 12:30:32      USD  2017-07-16 15:03:03   3000.0   330962986   \n",
       "4  2015-12-14 19:38:41      EUR  2016-02-13 01:56:30  15000.0  1657821447   \n",
       "\n",
       "           launched_at             ...             staff_pick       state  \\\n",
       "0  2016-11-05 18:42:23             ...                  False      failed   \n",
       "1  2015-07-21 12:00:34             ...                  False      failed   \n",
       "2  2015-04-15 16:22:34             ...                   True  successful   \n",
       "3  2017-06-01 15:03:03             ...                  False  successful   \n",
       "4  2015-12-15 01:56:30             ...                  False    canceled   \n",
       "\n",
       "      state_changed_at   usd_pledged  parent_category          category  \\\n",
       "0  2016-12-05 19:42:23    240.000000           crafts       woodworking   \n",
       "1  2015-08-24 12:00:34    247.950175              art          painting   \n",
       "2  2015-05-15 16:22:34  41738.000000             food       food trucks   \n",
       "3  2017-07-16 15:03:04   3115.000000       publishing  children's books   \n",
       "4  2016-02-10 00:54:26    660.680598     film & video    movie theaters   \n",
       "\n",
       "                                         project_url  \\\n",
       "0  https://www.kickstarter.com/projects/983022919...   \n",
       "1  https://www.kickstarter.com/projects/101531536...   \n",
       "2  https://www.kickstarter.com/projects/372111659...   \n",
       "3  https://www.kickstarter.com/projects/133655246...   \n",
       "4  https://www.kickstarter.com/projects/203240363...   \n",
       "\n",
       "                                         rewards_url  \\\n",
       "0  https://www.kickstarter.com/projects/983022919...   \n",
       "1  https://www.kickstarter.com/projects/101531536...   \n",
       "2  https://www.kickstarter.com/projects/372111659...   \n",
       "3  https://www.kickstarter.com/projects/133655246...   \n",
       "4  https://www.kickstarter.com/projects/203240363...   \n",
       "\n",
       "             project_duration      time_til_state_changed  \n",
       "0  84 days 21:36:32.000000000  84 days 21:36:32.000000000  \n",
       "1  44 days 21:01:02.000000000  44 days 21:01:02.000000000  \n",
       "2  51 days 22:41:20.000000000  51 days 22:41:20.000000000  \n",
       "3  59 days 02:32:31.000000000  59 days 02:32:32.000000000  \n",
       "4  60 days 06:17:49.000000000  57 days 05:15:45.000000000  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ks201901 = pd.read_csv(path)\n",
    "ks201901.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks201901[\"avg_backer_plegde\"] = ks201901['usd_pledged']/ks201901['backers_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks201901[\"avg_backer_plegde\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks201901.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ks201901)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ks201901[\"backers_count\"] = ks201901[\"backers_count\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_features = [\n",
    "    ['usd_pledged','category','parent_category','staff_pick','spotlight','backers_count','project_duration', 'time_til_state_changed'],\n",
    "    ['usd_pledged','category','parent_category','staff_pick','spotlight','backers_count','project_duration'],\n",
    "    ['usd_pledged','category','parent_category','staff_pick','spotlight','backers_count', 'time_til_state_changed'],\n",
    "    ['usd_pledged','category','parent_category','staff_pick','spotlight','project_duration', 'time_til_state_changed'],\n",
    "    ['usd_pledged','category','parent_category','staff_pick','backers_count','project_duration', 'time_til_state_changed'],\n",
    "    ['usd_pledged','category','parent_category','spotlight','backers_count','project_duration', 'time_til_state_changed'],\n",
    "    ['usd_pledged','category','staff_pick','spotlight','backers_count','project_duration', 'time_til_state_changed'],    \n",
    "    ['usd_pledged','parent_category','staff_pick','spotlight','backers_count','project_duration', 'time_til_state_changed'],\n",
    "    ['category','parent_category','staff_pick','spotlight','backers_count','project_duration', 'time_til_state_changed'],\n",
    "    ['usd_pledged','category','parent_category','staff_pick','spotlight','backers_count','project_duration', 'time_til_state_changed'],\n",
    "]\n",
    "#avg_backer_plegde = 'usd_pledged'/'backers_count'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knearestclassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "Y_train = ks201901[ks201901[\"state\"] != \"live\"]\n",
    "Y_train = Y_train[Y_train[\"state\"] != \"canceled\"]\n",
    "Y_train = Y_train[Y_train[\"state\"] != \"suspended\"]\n",
    "\n",
    "ks201901done = ks201901[(ks201901[\"state\"] != \"live\")]\n",
    "ks201901done = ks201901done[(ks201901done[\"state\"] != \"canceled\")]\n",
    "ks201901done = ks201901done[(ks201901done[\"state\"] != \"suspended\")]\n",
    "\n",
    "Y_train = Y_train[\"state\"]\n",
    "\n",
    "\n",
    "modelKnear = KNeighborsClassifier(n_neighbors=13)\n",
    "def get_accuracy(feats):\n",
    "    X_train = ks201901done[feats].fillna(\"\")\n",
    "    vec = DictVectorizer(sparse=False)\n",
    "\n",
    "    modelKnear = KNeighborsClassifier(n_neighbors=13)\n",
    "\n",
    "    pipeline = Pipeline([(\"vec\", vec), (\"model\", modelKnear)])\n",
    "    return cross_val_score(pipeline,X_train.to_dict(orient=\"records\"), Y_train,cv=5, scoring='accuracy').mean()\n",
    "\n",
    "#replace model with a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff[stuff[\"parent_category\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff[\"parent_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't use spotlight because this is something that you get after being successful in your project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stuff[stuff['backers_count'] == np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814722958522559"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy([\"avg_backer_plegde\", \"goal\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"avg_backer_plegde\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"avg_backer_plegde\", \"goal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"avg_backer_plegde\", \"goal\",'staff_pick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"backers_count\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below is the best model rn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9815807362530637"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy([\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"goal\",'staff_pick',\"backers_count\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "does staff pick deserve more weight in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"goal\",\"backers_count\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"goal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"goal\",'staff_pick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"avg_backer_plegde\", \"goal\",'staff_pick',\"backers_count\",\"usd_pledged\", 'parent_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\", 'parent_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\", 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"goal\",\"backers_count\",\"usd_pledged\", 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"staff_pick\", \"goal\",\"backers_count\",\"usd_pledged\", 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy([\"avg_backer_plegde\", \"goal\",'staff_pick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(feats):\n",
    "    X_train = ks201901done[feats].fillna(\"\")\n",
    "    vec = DictVectorizer(sparse=False)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=13)\n",
    "\n",
    "    pipeline = Pipeline([(\"vec\", vec), (\"model\", model)])\n",
    "    return cross_val_score(pipeline,X_train.to_dict(orient=\"records\"), Y_train,cv=5, scoring='f1_micro').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_f1([\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_f1([\"avg_backer_plegde\", \"goal\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_f1([\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_f1([\"avg_backer_plegde\", \"goal\",\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['backers_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['usd_pledged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['parent_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['staff_pick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['spotlight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['spotlight', 'staff_pick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['staff_pick', 'usd_pledged','backers_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['spotlight', 'usd_pledged','backers_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['usd_pledged','backers_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = Known.drop(columns = \"Author\")\n",
    "Y_train = ks201901[ks201901[\"state\"] != \"live\"]\n",
    "ks201901done = ks201901[ks201901[\"state\"] != \"live\"]\n",
    "Y_train = Y_train[\"state\"]\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy_k(k):\n",
    "    X_train = ks201901done[[\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\"]].fillna(\"\")\n",
    "    vec = DictVectorizer(sparse=False)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    pipeline = Pipeline([(\"vec\", vec), (\"model\", model)])\n",
    "    return cross_val_score(pipeline,X_train.to_dict(orient=\"records\"), Y_train,cv=5, scoring='accuracy').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_kspot(k):\n",
    "    X_train = ks201901done[['spotlight']].fillna(\"\")\n",
    "    vec = DictVectorizer(sparse=False)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    pipeline = Pipeline([(\"vec\", vec), (\"model\", model)])\n",
    "    return cross_val_score(pipeline,X_train.to_dict(orient=\"records\"), Y_train,cv=5, scoring='accuracy').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks1=pd.Series(index=range(1,50), data = range(1,50))\n",
    "#ks.index=range(1,100)\n",
    "#ks_df = pd.DataFrame(columns=[[\"accuracy\", \"f1\"]]) \n",
    "ks1.apply(get_accuracy_kspot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 is best for ['spotlight', 'usd_pledged','backers_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best is with neighbors of 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks=pd.Series(index=range(1,50), data = range(1,50))\n",
    "#ks.index=range(1,100)\n",
    "#ks_df = pd.DataFrame(columns=[[\"accuracy\", \"f1\"]]) \n",
    "ks.apply(get_accuracy_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff['spotlight'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['spotlight', 'usd_pledged', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "#so we will need a colmn that keeps the original utc times in order for us to properly plot this. and to use in our model.\n",
    "times = stuff['project_duration'].apply(datetime.utcfromtimestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['category','parent_category','staff_pick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['project_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['backers_count',\"usd_pledged\",'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['usd_pledged','category','parent_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['backers_count','category','project_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(['backers_count','project_duration','time_til_state_changed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(many_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = []\n",
    "for features in many_features:\n",
    "    acc_list.append(get_accuracy(features))\n",
    "#get_accuracy(['backers_count', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation of knearest neighbors\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# get the features (in dict format) and the labels\n",
    "# (do not split into training and validation sets)\n",
    "\n",
    "#beers_train_dict = beers_train[features1].to_dict(orient=\"records\")\n",
    "#do for tests.\n",
    "# do what we learned in 5.5\n",
    "# This is the format to do the k-fold cross validation from 5.5\n",
    "#This function works to bring back the CV score for any features I want to test.\n",
    "def get_CV_score (features):\n",
    "    ks201901_dict = ks201901[features].to_dict(orient=\"records\")\n",
    "    y = ks201901[\"usd_pledged\"]\n",
    "\n",
    "    # specify the pipeline\n",
    "    vec = DictVectorizer(sparse=False)\n",
    "    scaler = StandardScaler()\n",
    "    model = KNeighborsRegressor(n_neighbors=30)\n",
    "    pipeline = Pipeline([(\"vectorizer\", vec), (\"scaler\", scaler), (\"fit\", model)])\n",
    "    scores = cross_val_score(pipeline, ks201901_dict, y, \n",
    "                         cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    return np.mean(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks201901.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks201901[\"staff_pick\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_CV_score ([\"state\",'category','parent_category','staff_pick','spotlight','backers_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_CV_score (['backers_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_features=[]\n",
    "for features in many_features:\n",
    "    rmses_features.append(get_CV_score (features))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_201901[[\"backers_count\",\"usd_pledged\"]].plot.bar(x=\"backers_count\", y=\"usd_pledged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_train = ks201901[\"staff_pick\"]\n",
    "\n",
    "def get_acc(feats):\n",
    "    X_train = ks201901[feats].fillna(\"False\")\n",
    "    vec = DictVectorizer(sparse=False)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=13)\n",
    "\n",
    "    pipeline = Pipeline([(\"vec\", vec), (\"model\", model)])\n",
    "    return cross_val_score(pipeline,X_train.to_dict(orient=\"records\"), Y_train,cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc([\"staff_pick\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc([\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc([\"avg_backer_plegde\", \"goal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc([\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc([\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc([\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks201901.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks201901.blurb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy_k_tfidf_pt1(k):\n",
    "    Y_train = ks201901[ks201901[\"state\"] != \"live\"]\n",
    "    Y_train = Y_train[Y_train[\"state\"] != \"canceled\"]\n",
    "    Y_train = Y_train[Y_train[\"state\"] != \"suspended\"]\n",
    "    Y_train = Y_train[\"state\"]\n",
    "    Y_train = Y_train.loc[:1000]\n",
    "\n",
    "    ks201901done = ks201901[(ks201901[\"state\"] != \"live\")]\n",
    "    ks201901done = ks201901done[(ks201901done[\"state\"] != \"canceled\")]\n",
    "    ks201901done = ks201901done[(ks201901done[\"state\"] != \"suspended\")]\n",
    "    ks201901done = ks201901done.loc[:1000]\n",
    "\n",
    "    vec = TfidfVectorizer(max_features=50)\n",
    "    X_train = ks201901done.blurb.fillna(\"\")\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    pipeline = Pipeline([(\"vec\", vec), (\"model\", model)])\n",
    "    return cross_val_score(pipeline,X_train, Y_train,cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_accuracy_k_tfidf_pt2(k):\n",
    "    Y_train = ks201901[ks201901[\"state\"] != \"live\"]\n",
    "    Y_train = Y_train[Y_train[\"state\"] != \"canceled\"]\n",
    "    Y_train = Y_train[Y_train[\"state\"] != \"suspended\"]\n",
    "    Y_train = Y_train[\"state\"]\n",
    "    Y_train = Y_train.loc[1000:]\n",
    "\n",
    "    ks201901done = ks201901[(ks201901[\"state\"] != \"live\")]\n",
    "    ks201901done = ks201901done[(ks201901done[\"state\"] != \"canceled\")]\n",
    "    ks201901done = ks201901done[(ks201901done[\"state\"] != \"suspended\")]\n",
    "    ks201901done = ks201901done.loc[1000:]\n",
    "\n",
    "    vec = TfidfVectorizer(max_features=50)\n",
    "    X_train = ks201901done.blurb.fillna(\"\")\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    pipeline = Pipeline([(\"vec\", vec), (\"model\", model)])\n",
    "    return cross_val_score(pipeline,X_train, Y_train,cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = ks201901[ks201901[\"state\"] != \"live\"]\n",
    "Y_train = Y_train[Y_train[\"state\"] != \"canceled\"]\n",
    "Y_train = Y_train[Y_train[\"state\"] != \"suspended\"]\n",
    "Y_train = Y_train[\"state\"]\n",
    "Y_train\n",
    "\n",
    "ks201901done = ks201901[(ks201901[\"state\"] != \"live\")]\n",
    "ks201901done = ks201901done[(ks201901done[\"state\"] != \"canceled\")]\n",
    "ks201901done = ks201901done[(ks201901done[\"state\"] != \"suspended\")]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "def get_accurac_k_tf(k):\n",
    "    X_train = ks201901done.blurb.fillna(\"\")\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    pipeline = Pipeline([(\"vec\", vec), (\"model\", model)])\n",
    "    return cross_val_score(pipeline,X_train, Y_train,cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kstf=pd.Series(index=range(1,50), data = range(1,50))\n",
    "#ks.index=range(1,100)\n",
    "#ks_df = pd.DataFrame(columns=[[\"accuracy\", \"f1\"]]) \n",
    "kstf.apply(get_accurac_k_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy_k_tfidf(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks1=pd.Series(index=range(1,50), data = range(1,50))\n",
    "#ks.index=range(1,100)\n",
    "#ks_df = pd.DataFrame(columns=[[\"accuracy\", \"f1\"]]) \n",
    "ks1.apply(get_accuracy_k_tfidf_pt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks2=pd.Series(index=range(1,50), data = range(1,50))\n",
    "#ks.index=range(1,100)\n",
    "#ks_df = pd.DataFrame(columns=[[\"accuracy\", \"f1\"]]) \n",
    "ks2.apply(get_accuracy_k_tfidf_pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I must specify tol = tolerance and the max_iter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "Y_train = ks201901[ks201901[\"state\"] != \"live\"]\n",
    "Y_train = Y_train[Y_train[\"state\"] != \"canceled\"]\n",
    "Y_train = Y_train[Y_train[\"state\"] != \"suspended\"]\n",
    "\n",
    "ks201901done = ks201901[(ks201901[\"state\"] != \"live\")]\n",
    "ks201901done = ks201901done[(ks201901done[\"state\"] != \"canceled\")]\n",
    "ks201901done = ks201901done[(ks201901done[\"state\"] != \"suspended\")]\n",
    "\n",
    "Y_train = Y_train[\"state\"]\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy_line(feats):\n",
    "    X_train = ks201901done[feats].fillna(\"\")\n",
    "    vec = DictVectorizer(sparse=False)\n",
    "\n",
    "    modelSGD = SGDClassifier(max_iter=10000, tol=0)\n",
    "\n",
    "    pipeline = Pipeline([(\"vec\", vec), (\"model\", modelSGD)])\n",
    "    return cross_val_score(pipeline,X_train.to_dict(orient=\"records\"), Y_train,cv=5, scoring='accuracy').mean()\n",
    "\n",
    "#replace model with a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.910914154979937"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_line([\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125229671900798"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_line([\"backers_count\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6002395485841294"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_line([\"avg_backer_plegde\",\"goal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8284273932339683"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_line([\"avg_backer_plegde\",\"goal\",\"backers_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the best rn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9184740354332119"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_line([\"avg_backer_plegde\", \"goal\",\"usd_pledged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy_k_tfidf_sgd(max_i):\n",
    "    Y_train = ks201901[ks201901[\"state\"] != \"live\"]\n",
    "    Y_train = Y_train[Y_train[\"state\"] != \"canceled\"]\n",
    "    Y_train = Y_train[Y_train[\"state\"] != \"suspended\"]\n",
    "    Y_train = Y_train[\"state\"]\n",
    "    #Y_train = Y_train.loc[:10000]\n",
    "\n",
    "    ks201901done = ks201901[(ks201901[\"state\"] != \"live\")]\n",
    "    ks201901done = ks201901done[(ks201901done[\"state\"] != \"canceled\")]\n",
    "    ks201901done = ks201901done[(ks201901done[\"state\"] != \"suspended\")]\n",
    "    #ks201901done = ks201901done.loc[:10000]\n",
    "\n",
    "    vec = TfidfVectorizer(max_features=50)\n",
    "    X_train = ks201901done.blurb.fillna(\"\")\n",
    "    #model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model = SGDClassifier(max_iter=max_i, tol=1e-3)\n",
    "    pipeline = Pipeline([(\"vec\", vec), (\"model\", model)])\n",
    "    return cross_val_score(pipeline,X_train, Y_train,cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111661940891151"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_k_tfidf_sgd(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000    0.611156\n",
       "2000    0.611053\n",
       "3000    0.611249\n",
       "4000    0.611337\n",
       "5000    0.611182\n",
       "6000    0.611290\n",
       "7000    0.611275\n",
       "8000    0.611233\n",
       "9000    0.611218\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iters=pd.Series(index=range(1000,10000, 1000), data = range(1000,10000, 1000))\n",
    "#ks.index=range(1,100)\n",
    "#ks_df = pd.DataFrame(columns=[[\"accuracy\", \"f1\"]]) \n",
    "max_iters.apply(get_accuracy_k_tfidf_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class RegressionEnsembler(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"Creates an ensemble model out of a collection of individual estimators\n",
    "    \n",
    "    Args:\n",
    "      estimators: A list containing the individual estimators.\n",
    "      learn_weights: A boolean that specifies whether we should learn the\n",
    "        \"optimal\" weights/coefficients to apply to each individual estimator's\n",
    "        predictions. If False, we simply return the straight average of the \n",
    "        individual estimators' predictions as the ensemble prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, estimators, learn_weights=True):\n",
    "        self.estimators = estimators\n",
    "        self.learn_weights = learn_weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # check that X and y have the correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # store the training features and the labels\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        # call the fit method of each of the estimators\n",
    "        for estimator in self.estimators:\n",
    "            estimator.fit(X, y)\n",
    "            \n",
    "        # if we wish to learn the \"optimal\" weights from the training data\n",
    "        if self.learn_weights:\n",
    "            # get prediction from each estimator on the training data\n",
    "            predictions = []\n",
    "            for estimator in self.estimators:\n",
    "                predictions.append(estimator.predict(X))\n",
    "            Y_ = np.column_stack(predictions)\n",
    "        \n",
    "            # fit linear regression on top of the estimators' predictions\n",
    "            self.ensembler = LinearRegression(fit_intercept=False)\n",
    "            self.ensembler.fit(Y_, y)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # check that fit has been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "        \n",
    "        # check that X has the right form\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # calculate predictions from the estimators\n",
    "        predictions = []\n",
    "        for estimator in self.estimators:\n",
    "            predictions.append(estimator.predict(X))\n",
    "        Y_ = np.column_stack(predictions)\n",
    "        \n",
    "        # return predictions\n",
    "        if self.learn_weights:\n",
    "            return self.ensembler.predict(Y_)\n",
    "        else:\n",
    "            return Y_.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this didn't work :/ i still do not know how to ensemble ml models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKnear = KNeighborsClassifier(n_neighbors=13)\n",
    "modelSGD = SGDClassifier(max_iter=10000, tol=0)\n",
    "\n",
    "Y_train = ks201901[ks201901[\"state\"] != \"live\"]\n",
    "Y_train = Y_train[Y_train[\"state\"] != \"canceled\"]\n",
    "Y_train = Y_train[Y_train[\"state\"] != \"suspended\"]\n",
    "\n",
    "ks201901done = ks201901[(ks201901[\"state\"] != \"live\")]\n",
    "ks201901done = ks201901done[(ks201901done[\"state\"] != \"canceled\")]\n",
    "ks201901done = ks201901done[(ks201901done[\"state\"] != \"suspended\")]\n",
    "\n",
    "X_train = ks201901done[[\"avg_backer_plegde\", \"goal\",\"backers_count\",\"usd_pledged\"]]\n",
    "\n",
    "ensemble_model = RegressionEnsembler([modelKnear, modelSGD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-2d1576b932cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m (\n\u001b[1;32m      4\u001b[0m     -cross_val_score(modelKnear, X_train, Y_train,\n\u001b[0;32m----> 5\u001b[0;31m                      cv=20, scoring=\"accuracy\"),\n\u001b[0m\u001b[1;32m      6\u001b[0m     -cross_val_score(modelSGD, X_train, Y_train,\n\u001b[1;32m      7\u001b[0m                      cv=20, scoring=\"accuracy\"),\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[0;34m(cv, y, classifier)\u001b[0m\n\u001b[1;32m   2056\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m         if (classifier and (y is not None) and\n\u001b[0;32m-> 2058\u001b[0;31m                 (type_of_target(y) in ('binary', 'multiclass'))):\n\u001b[0m\u001b[1;32m   2059\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be class 'SparseSeries'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'multilabel-indicator'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    149\u001b[0m                  _is_integral_float(np.unique(y.data))))\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         return len(labels) < 3 and (y.dtype.kind in 'biu' or  # bool, int, uint\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "(\n",
    "    -cross_val_score(modelKnear, X_train, Y_train,\n",
    "                     cv=20, scoring=\"accuracy\"),\n",
    "    -cross_val_score(modelSGD, X_train, Y_train,\n",
    "                     cv=20, scoring=\"accuracy\"),\n",
    "    -cross_val_score(RegressionEnsembler([modelKnear, modelSGD], learn_weights=False), X_train, Y_train,\n",
    "                     cv=20, scoring=\"accuracy\"),\n",
    "    -cross_val_score(RegressionEnsembler([modelKnear, modelSGD], learn_weights=True), X_train, Y_train,\n",
    "                     cv=20, scoring=\"accuracy\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfr(data, X,Y, Title):\n",
    "    #data= dataframe that contains both input and output vars\n",
    "    #X is an array of input column names\n",
    "    #y is name of output column you are trying to predict\n",
    "    #Title = Title of the graph\n",
    "    \n",
    "    tests = {\n",
    "        \"Number of Estimators\" : [],\n",
    "        \"TestError\":[],\n",
    "    }\n",
    "    for k in range(1, 75):\n",
    "        model = RandomForestRegressor(n_estimators=k)\n",
    "        test_error = np.sqrt(-cross_val_score(\n",
    "                                 model,data[X], \n",
    "                                 data[Y],\n",
    "                                 cv = 10, \n",
    "                                 scoring=\"neg_mean_squared_error\"\n",
    "                                ).mean())\n",
    "        tests[\"Number of Estimators\"].append(k)\n",
    "        tests[\"TestError\"].append(test_error)\n",
    "        #print('.')\n",
    "    df = pd.DataFrame(tests)\n",
    "    ax = df.plot.scatter(\"Number of Estimators\",\"TestError\")\n",
    "    ax.set_xlabel(\"Number of Estimators\")\n",
    "    ax.set_ylabel(\"RMSE\")\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(16,6)\n",
    "    plt.title(Title)\n",
    "    return df.sort_values(\"TestError\").head(5)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
